<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Hao Zhao (赵皓)</title>
  
  <!-- <meta name="google-site-verification" content="lxQ58o9IgoHyhIPhGGRRwtddDCbfJ0ILZSk-7pjcid4" /> -->
  <meta name="author" content="Hao Zhao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Hao Zhao</name>
              </p>
              <p>I received the M.S. degree (with distinction in research) from the School of Engineering at <a href="https://www.epfl.ch/en/">EPFL</a> in February 2024, specializing in Automatic and Systems. Previously, I completed my master thesis at <a href="https://www.epfl.ch/labs/tml/">TML lab</a>, EPFL, supervised by <a href="https://people.epfl.ch/nicolas.flammarion?lang=en">Nicolas Flammarion</a>, and will continue my research at TML lab as a research assistant. I am interested in developing effective methods that enable AI systems to adapt efficiently to new environments and tasks. 
              </p>
              <p>
                During my master studies, I was also fortunate to spend time as a semester project student at <a href="https://www.epfl.ch/labs/vita/">VITA lab</a>, EPFL, supervised by <a href="https://people.epfl.ch/alexandre.alahi?lang=en">Alexandre Alahi</a>. I got my bachelor's degree from <a href="https://www.zju.edu.cn/english/">Zhejiang University</a>.
              </p>
              <p>
                I am actively looking for PhD positions starting from 2025 Fall and research assistant positions starting from 2024 Fall. If you think my background is a good fit, please don't hesitate to get in touch! 
              </p>
              <p style="text-align:center">
                <a href="mailto:hao.zhao@epfl.ch">Email</a> &nbsp/&nbsp
                <!-- <a href="data/CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="https://scholar.google.ca/citations?user=zir09KwAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp -->
                <a href="https://twitter.com/H_aoZhao">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/MarcellusZhao">GitHub</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/hao-zhao-/">LinkedIn</a>
                <!-- <a href="https://www.youtube.com/channel/UCmvUCGX9p6-azd2AetDRI8A">YouTube</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:80%;max-width:80%" alt="profile photo" src="images/selfie.JPG" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>What's New</heading>
              <p>[May 31, 2024] The short version of our work <a href="https://arxiv.org/abs/2405.19874">Is In-Context Learning Sufficient for Instruction Following in LLMs?</a> is available online (see this <a href="https://x.com/maksym_andr/status/1796574290797604892">Twitter/X thread</a> for a quick summary)!</p>
              <p>[May 02, 2024] One work on data selection for Instruction Fine-Tuning LLMs was accepted to <a href="https://icml.cc/">ICML 2024</a>. See (some of) you in Vienna again!</p>
              <p>[Mar 04, 2024] Our work <a href="https://arxiv.org/abs/2402.04833">Long Is More for Alignment: A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning</a> was accepted to Workshop <a href="https://dmlr.ai/">DMLR@ICLR'24</a>. Many thanks to anonymous reviewers for their constructive and helpful reviews!</p>
              <p>[Feb 29, 2024] I successfully defended my master thesis with a perfect grade of 6.0/6.0 and received nominations for EPFL Master Thesis Awards. Great thanks to my committee: <a href="https://people.epfl.ch/nicolas.flammarion?lang=en">Nicolas Flammarion</a>, <a href="https://people.epfl.ch/giancarlo.ferraritrecate">Giancarlo Ferrari Trecate</a>, <a href="https://tlin-taolin.github.io/">Tao Lin</a>, and my supervisors: <a href="https://www.andriushchenko.me/">Maksym Andriushchenko</a>, <a href="https://scholar.google.com/citations?user=laq9cq0AAAAJ&hl=zh-CN">Francesco Croce</a>.</p>
              <p>[Feb 07, 2024] Our new paper <a href="https://arxiv.org/abs/2402.04833">Long Is More for Alignment: A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning</a> is available online (see a <a href="https://twitter.com/maksym_andr/status/1755636355537715564">Twitter/X thread</a> for a summary). Great thanks to Maksym for spreading the word.</p>
              <p>[Jan 16, 2024] One work on Parameter-efficient Fine-tuning was accepted to <a href="https://iclr.cc/">ICLR 2024</a>. See you in Vienna!</p>
              <p>[Apr 25, 2023] One work on Test-time Adaptation was accepted to <a href="https://icml.cc/Conferences/2023">ICML 2023</a>.</p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <p>
                (* denotes equal contribution)
              </p>
              <!-- <p>  
                I'm interested in building machine learning systems that are robust, reliable, trustworthy, and understandable.
              </p> -->
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="icl_stop()" onmouseover="icl_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='icl_image'>
                  <img src='images/icl_alignment.jpeg' width="160"></div>
                <img src='images/icl_alignment.jpeg' width="160">
              </div>
              <script type="text/javascript">
                function icl_start() {
                  document.getElementById('icl_image').style.opacity = "1";
                }
  
                function icl_stop() {
                  document.getElementById('icl_image').style.opacity = "0";
                }
                icl_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2405.19874">
                <papertitle>Is In-Context Learning Sufficient for Instruction Following in LLMs?</papertitle>
              </a>
              <br>
              <strong>Hao Zhao</strong>, Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion
              <br>
              <em>Under review</em>
              <br>
              [<a href="https://arxiv.org/abs/2405.19874">arXiv</a>]
              [<a href="https://github.com/tml-epfl/icl-alignment">Code</a>]
              <p></p>
              <p>
                We uncover that, unlike for tasks such as classification, translation, or summarization, adding more ICL demonstrations for long-context LLMs does not systematically improve instruction following performance, even with more sophisticated approaches. Moreover, we show that for instruction-following tasks, the demonstrations need to be carefully chosen and of high quality, with correct answers to each question, which departs from findings in prior work (<a href="https://arxiv.org/abs/2202.12837">Min et al., 2022</a>).
              </p>
            </td>
          </tr>
          
          <tr onmouseout="lima_stop()" onmouseover="lima_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='lima_image'>
                  <img src='images/long_is_more_for_alignment.jpeg' width="160"></div>
                <img src='images/long_is_more_for_alignment.jpeg' width="160">
              </div>
              <script type="text/javascript">
                function lima_start() {
                  document.getElementById('lima_image').style.opacity = "1";
                }
  
                function lima_stop() {
                  document.getElementById('lima_image').style.opacity = "0";
                }
                lima_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2402.04833">
                <papertitle>Long Is More for Alignment: A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning</papertitle>
              </a>
              <br>
              <strong>Hao Zhao</strong>, Maksym Andriushchenko, Francesco Croce, Nicolas Flammarion
              <br>
              <em>ICML 2024, abridged in Workshop DMLR@ICLR'24</em>
              <br>
              [<a href="https://arxiv.org/abs/2402.04833">arXiv</a>]
              [<a href="https://huggingface.co/datasets/HuggingFaceH4/OpenHermes-2.5-1k-longest">HuggingFace</a>]
              [<a href="https://github.com/tml-epfl/long-is-more-for-alignment">Code</a>]
              <p></p>
              <p>
                We show that filtering via length heuristics is an effective and efficient approach to select instruction tuning data for alignment. In addition, we propose a lightweight refinement of long instructions which can further improve the abilities of the fine-tuned LLMs. In particular, we obtain the 2nd highest-ranked Llama-2-7B-based model on AlpacaEval 2.0 while training on only 1,000 examples and no extra preference data.
              </p>
            </td>
          </tr>


          <tr onmouseout="capaboost_stop()" onmouseover="capaboost_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='capaboost_image'>
                  <img src='images/CapaBoost.jpeg' width="160"></div>
                <img src='images/CapaBoost.jpeg' width="160">
              </div>
              <script type="text/javascript">
                function capaboost_start() {
                  document.getElementById('capaboost_image').style.opacity = "1";
                }
  
                function capaboost_stop() {
                  document.getElementById('capaboost_image').style.opacity = "0";
                }
                capaboost_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=H3IUunLy8s">
                <papertitle>Increasing Model Capacity for Free: A Simple Strategy for Parameter Efficient Fine-tuning
                </papertitle>
              </a>
              <br>
              Haobo Song*, <strong>Hao Zhao*</strong>, Soumajit Majumder, Tao Lin
              <br>
              <em>ICLR 2024</em>
              <br>
              <!-- <em>Links:</em> -->
              [<a href="https://openreview.net/forum?id=H3IUunLy8s">arXiv</a>]
              [<a href="https://github.com/LINs-lab/CapaBoost">Code</a>]
              <p></p>
              <p>
                We propose CapaBoost, a simple yet effective strategy that enhances model capacity by leveraging low-rank updates through parallel weight modules in target layers. By applying static random masks to the shared weight matrix, CapaBoost constructs a diverse set of weight matrices, effectively increasing the rank of incremental weights without adding parameters. Notably, our approach can be seamlessly integrated into various existing parameter-efficient fine-tuning methods.
              </p>
            </td>
          </tr>


          <tr onmouseout="ttab_stop()" onmouseover="ttab_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ttab_image'>
                  <img src='images/ttab.jpg' width="160"></div>
                <img src='images/ttab.jpg' width="160">
              </div>
              <script type="text/javascript">
                function ttab_start() {
                  document.getElementById('ttab_image').style.opacity = "1";
                }
  
                function ttab_stop() {
                  document.getElementById('ttab_image').style.opacity = "0";
                }
                ttab_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2306.03536">
                <papertitle>On Pitfalls of Test-Time Adaptation</papertitle>
              </a>
              <br>
              <strong>Hao Zhao*</strong> Yuejiang Liu*, Alexandre Alahi, Tao Lin
              <br>
              <em>ICML 2023, abridged in Workshop DG@ICLR'23 (spotlight)</em>
              <br>
              [<a href="https://arxiv.org/abs/2306.03536">arXiv</a>]
              [<a href="https://github.com/lins-lab/ttab?utm_source=catalyzex.com">Code</a>]
              <p></p>
              <p>
                We present TTAB, a test-time adaptation benchmark that encompasses ten state-of-the-art algorithms, a diverse array of distribution shifts, and two evaluation protocols. Through extensive experiments, our benchmark reveals three common pitfalls in prior efforts. Our findings underscore the need for future research in the field to conduct rigorous evaluations on a broader set of models and shifts, and to re-examine the assumptions behind the empirical success of TTA.
              </p>
            </td>
          </tr>
          

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Education</heading>
            <p> [2021.9 - 2024.2] M.S. in Automatic and Systems, <a href="https://www.epfl.ch/en/">EPFL</a>, Switzerland </p>
            <p> [2017.9 - 2021.6] B.Eng. in Mechanical Engineering, <a href="https://www.zju.edu.cn/english/">Zhejiang University</a>, China </p>
          </td>
        </tr>
        </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Review Service</heading>
          <p> Workshops:  <a href="https://dmlr.ai/">DMLR@ICLR'24</a>,  <a href="https://iclworkshop.github.io/#cfp">ICL@ICML'24</a>, <a href="https://want-ai-hpc.github.io/icml2024/about/">WANT@ICML'24</a> </p>
        </td>
      </tr>
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Miscellanea</heading>
          <p> When I'm not working, I enjoy strength training &#127947;, hiking &#127939;, and bouldering &#129495;. </p>
        </td>
      </tr>
      </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
            <br>
            <p align="right">
              <strong>I borrowed this website layout from <a target="_blank" href="https://jonbarron.info/">here</a>!</strong>
            </p>
            </td>
          </tr>
          </table>

      </td>
    </tr>
  </table>

  
</body>
</html>
