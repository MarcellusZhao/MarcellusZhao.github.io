<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Hao Zhao</title>
  
  <!-- <meta name="google-site-verification" content="lxQ58o9IgoHyhIPhGGRRwtddDCbfJ0ILZSk-7pjcid4" /> -->
  <meta name="author" content="Hao Zhao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <!-- <link rel="icon" type="image/png" href="images/seal_icon.png"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Hao Zhao (èµµçš“)</name>
              </p>
              <p>I received the M.S. degree (with distinction in research) from the School of Engineering at <a href="https://www.epfl.ch/en/">EPFL</a> <span>&#127464;&#127469;</span> in March 2024, specializing in Automatic and Systems. Previously, I completed my master thesis at <a href="https://www.epfl.ch/labs/tml/">TML lab</a>, EPFL, supervised by <a href="https://people.epfl.ch/nicolas.flammarion?lang=en">Prof. Nicolas Flammarion</a>, and will continue my research at TML lab as a research assistant. During my master studies, I was also fortunate to spend time as a semester project student at <a href="https://www.epfl.ch/labs/vita/">VITA lab</a>, EPFL, supervised by <a href="https://people.epfl.ch/alexandre.alahi?lang=en">Prof. Alexandre Alahi</a>. I got my bachelor's degree from <a href="https://www.zju.edu.cn/english/">Zhejiang University</a> <span>&#127464;&#127475;</span>.
              </p>
              <p>
                My research focuses on enhancing the efficiency of training and deploying advanced AI models while ensuring robustness, generalization performance, and safety. I'm interested in developing tools to understand the fundamental capabilities of LLMs and leveraging the insights I get to improve the efficiency and reliability of LLM alignment.
              </p>
              <p>
                I am actively looking for PhD positions starting from 2025 Fall. If you think my background is a good fit, please don't hesitate to get in touch! 
              </p>
              <p>
                For pronunciation, my full name <a href="https://www.howtopronounce.com/hao-zhao">/how-jow/</a>, but just my first name would be lot easier :)
              </p>
              <p style="text-align:center">
                <a href="https://scholar.google.com/citations?user=vwWiKP8AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="mailto:hao.zhao@epfl.ch">Email</a> &nbsp/&nbsp
                <!-- <a href="data/CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="https://scholar.google.ca/citations?user=zir09KwAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp -->
                <a href="https://twitter.com/H_aoZhao">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/MarcellusZhao">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/hao-zhao-/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:80%;max-width:80%" alt="profile photo" src="images/selfie.JPG" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>What's New</heading>
              <p>[Oct 10, 2024] Our work <a href="https://arxiv.org/abs/2405.19874">Is In-Context Learning Sufficient for Instruction Following in LLMs?</a> was accepted to Workshop <a href="https://adaptive-foundation-models.org/">AFM@NeurIPS'24</a> ðŸŽ‰. Many thanks to anonymous reviewers for their constructive and helpful reviews!</p>
              <p>[Oct 07, 2024] Our work on <a href="https://arxiv.org/abs/2405.19874">many-shot ICL</a> is featured by <a href="https://www.mittrchina.com/news/detail/13848">MIT Technology Review China</a> ðŸŽ‰!</p>
              <p>[Oct 07, 2024] A new version of our work <a href="https://arxiv.org/abs/2405.19874">Is In-Context Learning Sufficient for Instruction Following in LLMs?</a> is available online! See a <a href="https://x.com/maksym_andr/status/1844350642455732527">Twitter/X thread</a> for summary. Great thanks to Maksym for spreading the word.</p>
              <!-- <p>[May 31, 2024] The short version of our work <a href="https://arxiv.org/abs/2405.19874">Is In-Context Learning Sufficient for Instruction Following in LLMs?</a> is available online (see this <a href="https://x.com/maksym_andr/status/1796574290797604892">Twitter/X thread</a> for a quick summary)!</p> -->
              <p>[May 02, 2024] One work on data selection for Instruction Fine-Tuning LLMs was accepted to <a href="https://icml.cc/">ICML 2024</a>.</p>
              <!-- <p>[Mar 04, 2024] Our work <a href="https://arxiv.org/abs/2402.04833">Long Is More for Alignment: A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning</a> was accepted to Workshop <a href="https://dmlr.ai/">DMLR@ICLR'24</a>. Many thanks to anonymous reviewers for their constructive and helpful reviews!</p> -->
              <p>[Feb 29, 2024] I successfully defended my master thesis with a perfect grade of 6.0/6.0 and received nominations for EPFL Master Thesis Awards ðŸŽ‰. Great thanks to my committee: <a href="https://people.epfl.ch/nicolas.flammarion?lang=en">Nicolas Flammarion</a>, <a href="https://people.epfl.ch/giancarlo.ferraritrecate">Giancarlo Ferrari Trecate</a>, <a href="https://tlin-taolin.github.io/">Tao Lin</a>, and my supervisors: <a href="https://www.andriushchenko.me/">Maksym Andriushchenko</a>, <a href="https://scholar.google.com/citations?user=laq9cq0AAAAJ&hl=zh-CN">Francesco Croce</a>.</p>
              <!-- <p>[Feb 07, 2024] Our new paper <a href="https://arxiv.org/abs/2402.04833">Long Is More for Alignment: A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning</a> is available online (see a <a href="https://twitter.com/maksym_andr/status/1755636355537715564">Twitter/X thread</a> for a summary). Great thanks to Maksym for spreading the word.</p> -->
              <p>[Jan 16, 2024] One work on Parameter-efficient Fine-tuning was accepted to <a href="https://iclr.cc/">ICLR 2024</a>.</p>
              <p>[Apr 25, 2023] One work on Test-time Adaptation was accepted to <a href="https://icml.cc/Conferences/2023">ICML 2023</a>.</p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
              <p>
                (* denotes equal contribution)
              </p>
              <!-- <p>  
                I'm interested in building machine learning systems that are robust, reliable, trustworthy, and understandable.
              </p> -->
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="icl_stop()" onmouseover="icl_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='icl_image'>
                  <img src='images/many-shot-icl-teaser.jpeg' width="160"></div>
                <img src='images/many-shot-icl-teaser.jpeg' width="160">
              </div>
              <script type="text/javascript">
                function icl_start() {
                  document.getElementById('icl_image').style.opacity = "1";
                }
  
                function icl_stop() {
                  document.getElementById('icl_image').style.opacity = "0";
                }
                icl_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2405.19874">
                <papertitle>Is In-Context Learning Sufficient for Instruction Following in LLMs?</papertitle>
              </a>
              <br>
              <strong>Hao Zhao</strong>, <a href="https://www.andriushchenko.me/">Maksym Andriushchenko</a>, <a href="https://scholar.google.com/citations?user=laq9cq0AAAAJ&hl=en">Francesco Croce</a>, <a href="https://people.epfl.ch/nicolas.flammarion?lang=en">Nicolas Flammarion</a>
              <br>
              <em>Under review, abridged in Workshop AFM@NeurIPS'24</em>
              <br>
              [<a href="https://arxiv.org/abs/2405.19874">arXiv</a>]
              [<a href="https://github.com/tml-epfl/icl-alignment">Code</a>]
              [<a href="https://www.mittrchina.com/news/detail/13848">MIT Tech Review China</a>]
              <p></p>
              <p>
                In this work, we show that, while effective, ICL alignment with URIAL (<a href="https://arxiv.org/abs/2312.01552">Lin et al., 2024</a>) still underperforms compared to instruction fine-tuning on the established benchmark MT-Bench, especially with more capable base LLMs, such as GPT-4-Base. We then uncover the most relevant elements for successful in-context alignment, finding the crucial role of the decoding parameters. Based on these insights, we show that the approach of URIAL can indeed be improved by adding high-quality, possibly carefully selected via greedy search, demonstrations in context, getting closer to the performance of instruct models. Finally, we provide the first, to our knowledge, systematic comparison of ICL and instruction fine-tuning (IFT) for instruction following in the low data regime, where ICL can be a viable alternative to IFT.
              </p>
            </td>
          </tr>
          
          <tr onmouseout="lima_stop()" onmouseover="lima_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='lima_image'>
                  <img src='images/long-is-more.png' width="160"></div>
                <img src='images/long-is-more.png' width="160">
              </div>
              <script type="text/javascript">
                function lima_start() {
                  document.getElementById('lima_image').style.opacity = "1";
                }
  
                function lima_stop() {
                  document.getElementById('lima_image').style.opacity = "0";
                }
                lima_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2402.04833">
                <papertitle>Long Is More for Alignment: A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning</papertitle>
              </a>
              <br>
              <strong>Hao Zhao</strong>, <a href="https://www.andriushchenko.me/">Maksym Andriushchenko</a>, <a href="https://scholar.google.com/citations?user=laq9cq0AAAAJ&hl=en">Francesco Croce</a>, <a href="https://people.epfl.ch/nicolas.flammarion?lang=en">Nicolas Flammarion</a>
              <br>
              <em>ICML 2024, abridged in Workshop DMLR@ICLR'24</em>
              <br>
              [<a href="https://arxiv.org/abs/2402.04833">arXiv</a>]
              [<a href="https://huggingface.co/datasets/HuggingFaceH4/OpenHermes-2.5-1k-longest">HuggingFace</a>]
              [<a href="https://github.com/tml-epfl/long-is-more-for-alignment">Code</a>]
              <p></p>
              <p>
                Prior works demonstrate that instruction fine-tuning (IFT) of base LLMs over multi-million-example datasets enables them to fluently interact with human users. We show that filtering via length heuristics is an effective and efficient approach to select instruction tuning data for alignment, and find that fine-tuning on 1K instructions with the longest responses from large-scale IFT datasets, such as Alpaca, outperforms fine-tuning on full datasets. It validates the <a href="https://arxiv.org/abs/2305.11206">Superficial Alignment Hypothesis</a>, which suggests that very few samples are sufficient to teach base LLMs to follow natural language instructions. In addition, we propose to refine pre-selected examples using GPT-4-Turbo, based on its exceptional judging and introspecting capabilities. The resulting dataset, consisting of only 1K instruction-response pairs, yielded competitive results on AlpacaEval 2.0 and MT-Bench compared to complex alignment approaches like RLHF and DPO.
              </p>
            </td>
          </tr>


          <tr onmouseout="capaboost_stop()" onmouseover="capaboost_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='capaboost_image'>
                  <img src='images/CapaBoost.jpeg' width="160"></div>
                <img src='images/CapaBoost.jpeg' width="160">
              </div>
              <script type="text/javascript">
                function capaboost_start() {
                  document.getElementById('capaboost_image').style.opacity = "1";
                }
  
                function capaboost_stop() {
                  document.getElementById('capaboost_image').style.opacity = "0";
                }
                capaboost_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openreview.net/forum?id=H3IUunLy8s">
                <papertitle>Increasing Model Capacity for Free: A Simple Strategy for Parameter Efficient Fine-tuning
                </papertitle>
              </a>
              <br>
              Haobo Song*, <strong>Hao Zhao*</strong>, Soumajit Majumder, <a href="https://tlin-taolin.github.io/">Tao Lin</a>
              <br>
              <em>ICLR 2024</em>
              <br>
              <!-- <em>Links:</em> -->
              [<a href="https://arxiv.org/abs/2407.01320">arXiv</a>]
              [<a href="https://github.com/LINs-lab/CapaBoost">Code</a>]
              <p></p>
              <p>
                The core idea of Parameter-Efficient Fine-Tuning (PEFT) methods, such as LoRA, is to model the incremental update of pre-trained weights (&Delta W) through low-rank approximations BA, where A and B are trainable weight matrices.
                We propose CapaBoost, a simple yet effective strategy that enhances model capacity by leveraging low-rank updates through parallel weight modules in target layers. By applying static random masks to the shared weight matrix, CapaBoost constructs a diverse set of weight matrices, effectively increasing the rank of incremental weights without adding parameters. Notably, our approach can be seamlessly integrated into various existing parameter-efficient fine-tuning methods.
              </p>
            </td>
          </tr>


          <tr onmouseout="ttab_stop()" onmouseover="ttab_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ttab_image'>
                  <img src='images/ttab.jpg' width="160"></div>
                <img src='images/ttab.jpg' width="160">
              </div>
              <script type="text/javascript">
                function ttab_start() {
                  document.getElementById('ttab_image').style.opacity = "1";
                }
  
                function ttab_stop() {
                  document.getElementById('ttab_image').style.opacity = "0";
                }
                ttab_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2306.03536">
                <papertitle>On Pitfalls of Test-Time Adaptation</papertitle>
              </a>
              <br>
              <strong>Hao Zhao*</strong> Yuejiang Liu*, Alexandre Alahi, Tao Lin
              <br>
              <em>ICML 2023, abridged in Workshop DG@ICLR'23 (spotlight)</em>
              <br>
              [<a href="https://arxiv.org/abs/2306.03536">arXiv</a>]
              [<a href="https://github.com/lins-lab/ttab?utm_source=catalyzex.com">Code</a>]
              <p></p>
              <p>
                We present TTAB, a test-time adaptation benchmark that encompasses ten state-of-the-art algorithms, a diverse array of distribution shifts, and two evaluation protocols. Through extensive experiments, our benchmark reveals three common pitfalls in prior efforts. Our findings underscore the need for future research in the field to conduct rigorous evaluations on a broader set of models and shifts, and to re-examine the assumptions behind the empirical success of TTA.
              </p>
            </td>
          </tr>
          

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Education</heading>
            <p> [2021.9 - 2024.2] M.S. in Automatic and Systems, <a href="https://www.epfl.ch/en/">EPFL</a>, Switzerland </p>
            <p> [2017.9 - 2021.6] B.Eng. in Mechanical Engineering, <a href="https://www.zju.edu.cn/english/">Zhejiang University</a>, China </p>
          </td>
        </tr>
        </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Review Service</heading>
          <p> Conferences: <a href="https://iclr.cc/">ICLR'25</a>  </p>
          <p> Workshops:  <a href="https://sites.google.com/view/neurips2024-ftw/">FITML@NeurIPS'24</a>,  <a href="https://iclworkshop.github.io/#cfp">ICL@ICML'24</a>, <a href="https://want-ai-hpc.github.io/icml2024/about/">WANT@ICML'24</a>, <a href="https://dmlr.ai/">DMLR@ICLR'24</a> </p>
        </td>
      </tr>
      </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Miscellanea</heading>
          <p> When I'm not working, I enjoy strength training &#127947;, hiking &#127939;, and swimming &#127946;. </p>
        </td>
      </tr>
      </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
            <br>
            <p align="right">
              <strong>I borrowed this website layout from <a target="_blank" href="https://jonbarron.info/">here</a>!</strong>
            </p>
            </td>
          </tr>
          </table>

      </td>
    </tr>
  </table>

  
</body>
</html>
